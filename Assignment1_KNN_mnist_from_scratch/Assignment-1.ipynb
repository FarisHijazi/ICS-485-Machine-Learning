{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 (KNN Classifier)\n",
    "## Handwritten digit recognition\n",
    "In this assignment, we will build a classifier that takes an image of a handwritten digit and outputs a label 0-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "`MNIST` is a classic dataset in machine learning, consisting of 28x28 gray-scale images handwritten digits. The training set contains 60,000 examples and the test set contains 10,000 examples. In this assignment we will further split the training set to take out 12,000 examples as a validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gzip, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "## Load the training set\n",
    "train_data = np.load('MNIST/train_data.npy')\n",
    "train_labels = np.load('MNIST/train_labels.npy')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = np.load('MNIST/test_data.npy')\n",
    "test_labels = np.load('MNIST/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset dimensions:  (60000, 784)\n",
      "Number of training labels:  60000\n",
      "Testing dataset dimensions:  (10000, 784)\n",
      "Number of testing labels:  10000\n"
     ]
    }
   ],
   "source": [
    "## Print out their dimensions\n",
    "print(\"Training dataset dimensions: \", np.shape(train_data))\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Testing dataset dimensions: \", np.shape(test_data))\n",
    "print(\"Number of testing labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Test set distribution:\n",
      "{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "## Compute the number of examples of each digit\n",
    "train_digits, train_counts = np.unique(train_labels, return_counts=True)\n",
    "print(\"Training set distribution:\")\n",
    "print(dict(zip(train_digits, train_counts)))\n",
    "\n",
    "test_digits, test_counts = np.unique(test_labels, return_counts=True)\n",
    "print(\"Test set distribution:\")\n",
    "print(dict(zip(test_digits, test_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7\n"
     ]
    }
   ],
   "source": [
    "## Define a function that displays a digit given its vector representation\n",
    "def show_digit(x):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "## Define a function that takes an index into a particular data set (\"train\" or \"test\") and displays that image.\n",
    "def vis_image(index, dataset=\"train\"):\n",
    "    if(dataset==\"train\"): \n",
    "        show_digit(train_data[index,])\n",
    "        label = train_labels[index]\n",
    "    else:\n",
    "        show_digit(test_data[index,])\n",
    "        label = test_labels[index]\n",
    "    print(\"Label \" + str(label))\n",
    "    return\n",
    "\n",
    "## View the first data point in the training set\n",
    "vis_image(0, \"train\")\n",
    "\n",
    "## Now view the first data point in the test set\n",
    "vis_image(0, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, valx, trainy, valy = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification with L2 distance\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. A natural distance function is _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Often we omit the square root, and simply compute _squared Euclidean distance_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`evalx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L2(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L2**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `evalx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L1(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L1**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification and L1 distance metric. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), the value of **K** (integer), and a parameter for deciding the distance metric to be used (fr example 1 for L1 and 2 for L2) and predicts labels for these test points using KNN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that allows you to select the hyper-parameters (distance measure and the value of K) by calling the KNN classifier with different values of K and either L1 or L2 distance measure. Make sure that you set the hyper-parameters using the development set and not the test set. You need to systemtically try different values for K in conjunction with a distance measure and tabulate the results (in the assignment report) and not down the best hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the hyper-parameters have been selected, we now would like to perform a final evaluation on the test set and record the error rates. Also, Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array` of shape `(10,10)`. Also, record the confusion matrix in your assignment report.\n",
    "\n",
    "**Note:** Record the cpu time it takes to perform the evaluation on the test set using functions like **time.time()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(testy, testy_fit):\n",
    "    # inputs: the correct labels, the fitted KNN labels \n",
    "    # output: a 10x10 np.array representing the confusion matrix as above\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    return None\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for performing the final evaluation on the test set and generating the confuson matrix.\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Faster nearest neighbor methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\n",
    "\n",
    "Fortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data structures: the _ball tree_ and the _k-d tree_. Study the KDTree and use it to make KNN predictions. Record the error rates on the test set and the cpu time taken for evaluation.\n",
    "\n",
    "**Note:** Here you don't have to implement teh KDTree but just you need to use it from ``sklearn`` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Preparing the assignment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to prepare the assignment report and submit your code and report to the Blackboard assignment. You need to record your answers for the following questions in the report:\n",
    "1. What is the error rate on the validation set for NN_L2?\n",
    "2. What is the best error rate on the validation set for KNN_L2?\n",
    "3. What is the error rate on the validation set for NN_L1?\n",
    "4. What is the best error rate on the validation set for KNN_L1?\n",
    "5. What is the error rate on the test set?\n",
    "6. Which digit class has the most errorrs? And, with which class does it get the most confused? Do you have ideas to fix this problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Implementing weighted KNN where the vote of a neighbour is scaled down based on its distance from the test point.\n",
    "3. Implement L_infinity distance measure and use it for classification.\n",
    "2. Instead of using the pixels as features, implement your own features (example: what were presented in the slides) and use them for KNN. You need to keep in mind that if you compute features which have different scales then it is important to scale/normalize the features (discussed in the slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
