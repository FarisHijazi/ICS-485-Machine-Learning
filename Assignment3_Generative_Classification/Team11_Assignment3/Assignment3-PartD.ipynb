{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype(\"int64\")\n",
    "test_data = test_data.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data = train_data[:int(len(train_data)*0.1),:]\n",
    "train_labels = train_labels[:int(len(train_labels)*0.1)]\n",
    "\n",
    "test_data = train_data[:int(len(test_data)*0.1),:]\n",
    "test_labels = train_labels[:int(len(test_labels)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (12000, 784), (48000,), (12000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the IRIS example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a hyper-parameter, and by setting it appropriately, we can improve the performance of the model.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x, y, c):\n",
    "    ### UPDATE CODE HERE ###\n",
    "    #c = 100\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    for label in range(0,k):\n",
    "        indices = (y == label)\n",
    "        ### START CODE HERE ###\n",
    "        mu[label] = x[indices,:].mean(axis = 0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=False)\n",
    "        ### Update Code for regularization (smoothing)\n",
    "        sigma[label] = sigma[label] + c*np.identity(d)\n",
    "        pi[label] = len(x[indices,:]) / len(y)\n",
    "        ### END CODE HERE ###\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(X_train, Y_train, 1000000000000)\n",
    "\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(10, 784, 784)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(mu.shape)\n",
    "print(sigma.shape)\n",
    "print(pi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on validate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the validate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalPDF(x, mu, ConstantPart, invCovar, pi):\n",
    "    \n",
    "    expPart = np.matmul(np.matmul(-0.5 *np.transpose(x - mu), invCovar), x-mu)\n",
    "    #expPart = np.log(expPart)\n",
    "    #consPart = ConstantPart\n",
    "    #consPast = np.log(consPart)\n",
    "    #res = pi * (expPart - consPart)\n",
    "    res = expPart - (ConstantPart) + np.log(pi)\n",
    "    \n",
    "    return res\n",
    "# def NormalPDF(x, mu, covar, pi):\n",
    "#     d = len(mu)\n",
    "#     expPart = np.matmul(np.matmul(-0.5 *np.transpose(x - mu), np.linalg.inv(covar)), x-mu)\n",
    "#     pa1 = (d/2)*np.log(2+np.pi)\n",
    "#     pa2 = np.sqrt(np.linalg.det(covar))\n",
    "#     res = np.log(pi) + expPart - (pa1 + pa2)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 10678 errors out of 12000\n",
      "Accuracy = 11.016666666666666\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [val image,label] pair.\n",
    "k = 10\n",
    "score = np.zeros((Y_val.shape[0],k))\n",
    "for label in range(0,k):\n",
    "    invCovar = np.linalg.inv(sigma[label])\n",
    "    d = len(mu[label])\n",
    "    #ConstantPart = (np.power(2*np.pi, d/2)* np.sqrt(np.linalg.det(sigma[label])))\n",
    "    ConstantPart = (d/2) * np.log(2*np.pi) + 0.5 * np.linalg.slogdet(sigma[label])[1]\n",
    "    for i in range(0,Y_val.shape[0]):\n",
    "       ### START CODE HERE ###\n",
    "       #score[i,label] = multivariate_normal.logpdf(X_val[i], mu[label], sigma[label]) * pi[label]\n",
    "        score[i,label] = NormalPDF(X_val[i], mu[label], ConstantPart, invCovar, pi[label])\n",
    "\n",
    "predictions = np.argmax(score, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != Y_val)\n",
    "print (\"Your model makes \" + str(errors) + \" errors out of 12000\")\n",
    "print(\"Accuracy = \" + str((12000-errors)/12000*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pick_C(c):\n",
    "    mu, sigma, pi = fit_generative_model(X_train, Y_train, c)\n",
    "    k = 10\n",
    "    score = np.zeros((Y_val.shape[0],k))\n",
    "    for label in range(0,k):\n",
    "        invCovar = np.linalg.inv(sigma[label])\n",
    "        d = len(mu[label])\n",
    "        #ConstantPart = (np.power(2*np.pi, d/2)* np.sqrt(np.linalg.det(sigma[label])))\n",
    "        ConstantPart = (d/2) * np.log(2*np.pi) + 0.5 * np.linalg.slogdet(sigma[label])[1]\n",
    "        for i in range(0,Y_val.shape[0]):\n",
    "           ### START CODE HERE ###\n",
    "           #score[i,label] = multivariate_normal.logpdf(X_val[i], mu[label], sigma[label]) * pi[label]\n",
    "            score[i,label] = NormalPDF(X_val[i], mu[label], ConstantPart, invCovar, pi[label])\n",
    "\n",
    "    predictions = np.argmax(score, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != Y_val)\n",
    "    print(\"C = %d\"%(c))\n",
    "    print (\"Your model makes \" + str(errors) + \" errors out of 12000\")\n",
    "    print(\"Accuracy = \" + str((12000-errors)/12000*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 100\n",
      "Your model makes 1045 errors out of 12000\n",
      "Accuracy = 91.29166666666667\n",
      "C = 150\n",
      "Your model makes 948 errors out of 12000\n",
      "Accuracy = 92.10000000000001\n",
      "C = 300\n",
      "Your model makes 807 errors out of 12000\n",
      "Accuracy = 93.27499999999999\n",
      "C = 500\n",
      "Your model makes 724 errors out of 12000\n",
      "Accuracy = 93.96666666666667\n",
      "C = 700\n",
      "Your model makes 684 errors out of 12000\n",
      "Accuracy = 94.3\n",
      "C = 1000\n",
      "Your model makes 633 errors out of 12000\n",
      "Accuracy = 94.72500000000001\n",
      "C = 1500\n",
      "Your model makes 598 errors out of 12000\n",
      "Accuracy = 95.01666666666667\n",
      "C = 2000\n",
      "Your model makes 581 errors out of 12000\n",
      "Accuracy = 95.15833333333333\n",
      "C = 3000\n",
      "Your model makes 583 errors out of 12000\n",
      "Accuracy = 95.14166666666667\n"
     ]
    }
   ],
   "source": [
    "c = [100, 150, 300, 500, 700, 1000, 1500, 2000, 3000]\n",
    "\n",
    "for i in c:\n",
    "    Pick_C(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, pi = fit_generative_model(X_train, Y_train, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 439 errors out of 10000\n",
      "Accuracy = 95.61\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [val image,label] pair.\n",
    "k = 10\n",
    "score = np.zeros((test_labels.shape[0],k))\n",
    "for label in range(0,k):\n",
    "    invCovar = np.linalg.inv(sigma[label])\n",
    "    d = len(mu[label])    \n",
    "    ConstantPart = (d/2) * np.log(2*np.pi) + 0.5 * np.linalg.slogdet(sigma[label])[1]\n",
    "    for i in range(0,test_labels.shape[0]):\n",
    "       ### START CODE HERE ### \n",
    "       score[i,label] = NormalPDF(test_data[i], mu[label], ConstantPart, invCovar, pi[label])\n",
    "predictions = np.argmax(score, axis = 1)\n",
    "### END CODE HERE ###\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "total_count = test_labels.shape[0]\n",
    "print (\"Your model makes \" + str(errors) + \" errors out of \" + str(total_count))\n",
    "print(\"Accuracy = \" + str((total_count-errors)/total_count*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 4:</font> How many errors did your model make on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Optional</font>: \n",
    "1. We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?\n",
    "2. Try applying multivariate Gaussian classifier on other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
