{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will create a **gradient descent** solver for **ridge regression** and **lasso regression** then compare it to the built-in libraries in `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook and load data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in some standard packages, we load synthetic data set consisting of data points `(x,y)`:\n",
    "* `x`: 100-dimensional vector whose coordinates are independent draws from a standard normal (Gaussian) distribution\n",
    "* `y`: response value given by `y = wx + e` where `w` is a target regression function and `e` is Gaussian noise. **`y` was generated using only 10 of the 100 features (which are unknown to you, at least for now!).**}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next snippet of code loads in the dataset. There are 100 data points for train and test set respectively, each with 100 predictor variables (which we'll denote `x`) and one response variable (which we'll denote `y`).\n",
    "\n",
    "Make sure the files `'trainx.csv'`,`'trainy.csv'`,`'testx.csv'`, and `'testy.csv'` are in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "trainx (100, 100) \ntrainy (1, 100) \ntestx (100, 100) \ntesty (1, 100)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "trainx = np.genfromtxt('trainx.csv', delimiter=',')\n",
    "testx = np.genfromtxt('testx.csv', delimiter=',')\n",
    "trainy = np.genfromtxt('trainy.csv', delimiter=',')[np.newaxis]\n",
    "testy = np.genfromtxt('testy.csv', delimiter=',')[np.newaxis]\n",
    "\n",
    "# scaling\n",
    "trainy = StandardScaler().fit(trainy).transform(trainy)\n",
    "trainx = StandardScaler().fit(trainx).transform(trainx)\n",
    "testy = StandardScaler().fit(testy).transform(testy)\n",
    "testx = StandardScaler().fit(testx).transform(testx)\n",
    "\n",
    "\n",
    "print('trainx', trainx.shape,\n",
    "      '\\ntrainy', trainy.shape,\n",
    "      '\\ntestx', testx.shape,\n",
    "      '\\ntesty', testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient descent solver for ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do:**</font> Define a procedure, **ridge_regression_GD**, that uses gradient descent to solve the ridge regression problem. It is invoked as follows:\n",
    "\n",
    "* `w,b,losses = ridge_regression_GD(x,y,C)`\n",
    "\n",
    "Here, the input consists of:\n",
    "* training data `trainx, trainy`, where `trainx` and `trainy` are numpy arrays of dimension `m`-by-`n` and `m`, respectively (if there are `m` training points and `n` features)\n",
    "* regularization constant `C`, we normally use the term **lambda**.\n",
    "\n",
    "The function should find the `n`-dimensional vector `w` and offset `b` that minimize the MSE loss function (with regularization constant `C`), and return:\n",
    "* `w` and `b`\n",
    "* `losses`, an array containing the MSE loss at each iteration\n",
    "\n",
    "<font color=\"magenta\">Advice:</font> First figure out the derivative, which has a relatively simple form. Next, when implementing gradient descent, think carefully about two issues.\n",
    "\n",
    "1. What is the step size (learning rate)?\n",
    "2. When has the procedure converged?\n",
    "\n",
    "Take the time to experiment with different ways of handling these.\n",
    "\n",
    "**Note:** You can use additional methods as helpers if you feel the need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# m: the number of samples\n",
    "\n",
    "def concat_bias_column_as_feature(X):\n",
    "    \"\"\"@param X - the training featuers m by n, appends a bias column as 1's to the beginning\"\"\"\n",
    "    return np.hstack((np.ones(X.shape[0])[np.newaxis].T, X)) # adding a column of 1's (this is for the bias)\n",
    "\n",
    "def predict(X, W):\n",
    "    return np.dot(X, W)\n",
    "\n",
    "def loss(X, Y, W, C=0, ridge=False):\n",
    "    \"\"\"\n",
    "    @param c - the regularization constant\n",
    "    @param ridge - if True, will compute \"Ridge\" regularization\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    Y_hat = predict(X, W)\n",
    "    reg_term = np.linalg.norm(W) ** 2 if ridge else np.linalg.norm(W)\n",
    "\n",
    "    return 1.0/2.0 * np.mean((Y - Y_hat) ** 2) + C * reg_term / m\n",
    "\n",
    "\n",
    "def loss_derivative(X, Y, W, C=0, ridge=False):\n",
    "    m = X.shape[1]\n",
    "    reg_term = 2 * np.linalg.norm(W) if ridge else 1\n",
    "    \n",
    "    return -1.0 / m * (np.sum(np.dot(Y - predict(X, W), X)) + C * reg_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def regression_GD_general(x, y, C=0, ridge=False, n_epochs=1e4, lr=0.001, epsilon=1e-14, random_state=None):\n",
    "    \"\"\"\n",
    "    :param x: training data points\n",
    "    :param y: training labels\n",
    "    :param C: regularization constant\n",
    "    :param ridge: boolean, True if ridge regularization, else Lasso\n",
    "    :param n_epochs: \n",
    "    :param lr: learning rate\n",
    "    :param epsilon: stop when delta_loss < epsilon\n",
    "    :param random_state: random seed for weight initialization\n",
    "    :return: w, b, training_losses\n",
    "    \"\"\"\n",
    "    # adding the bias in the beginning of the X (to make things simpler)\n",
    "    X = concat_bias_column_as_feature(x)\n",
    "    \n",
    "    np.random.seed(random_state) # setting random seed for weight initialization\n",
    "    # creating a weights vector that contains the bias as well\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    Y = y\n",
    "    m = X.shape[1]\n",
    "    \n",
    "#     print(\"X:\", X.shape)\n",
    "#     print(\"Y:\", Y.shape)\n",
    "#     print(\"W:\", W.shape)\n",
    "\n",
    "    last_loss = np.Inf\n",
    "    training_losses = []\n",
    "    for e in range(int(n_epochs)):\n",
    "        delta_W = loss_derivative(X, y, W, C=C, ridge=ridge)\n",
    "#         print('delta_W',delta_W.shape)\n",
    "        err = loss(X, y, W, C=C, ridge=ridge)\n",
    "        \n",
    "        W = W - lr * ( delta_W)  # updating weights\n",
    "\n",
    "        # print(\"{}: Loss={}\".format(e, err))\n",
    "        # the bellow is just logging/printing stuff\n",
    "        training_losses.append(err)\n",
    "        if np.abs(err - last_loss) < epsilon:\n",
    "            print(f'STOPPING EARLY at epoch {e} (epsilon={epsilon})')\n",
    "            break\n",
    "        else:\n",
    "            last_loss = err\n",
    "\n",
    "    w, b = W[1:], W[0] # splitting the joint weights:bias, into 2 variables\n",
    "    \n",
    "    print('final loss={:.5f}'.format(training_losses[-1]))\n",
    "    return w, b, training_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def ridge_regression_GD(x, y, C, **kwargs):\n",
    "    return regression_GD_general(x, y, C, ridge=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out and print a graph of the loss values during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "STOPPING EARLY at epoch 254 (epsilon=1e-14)\nfinal loss=47.92181\n",
      "|W|=10.47\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set regularization constant\n",
    "C = 1.0 # you can try different values for C\n",
    "# Run gradient descent solver\n",
    "w, b, losses = ridge_regression_GD(trainx, trainy, C, n_epochs=1e4, lr=0.001, epsilon=1e-14, random_state=9)\n",
    "# Plot the losses\n",
    "plt.plot(losses,'r')\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('|W|={:.2f}'.format(np.linalg.norm(w)))\n",
    "# print('W=', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate the gradient descent solver for ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the regressor found by your gradient descent procedure to that returned by the built-in ridge regression solver in `sklearn`. We will compare them by their resulting MSE values. We will also compare the results of the built-in linear regression (without regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code to compute the MSE value given `w`, `b`, `x`, and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_mse(w,b,x,y):\n",
    "    ### START CODE HERE ###\n",
    "    X = concat_bias_column_as_feature(x) # adding the bias in the beginning of the X (to make things simpler)\n",
    "    W = np.hstack((b, w))\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    Y_hat = predict(X, W)\n",
    "    return 1.0/(2.0 * m) * np.sum((y - Y_hat) ** 2)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPPING EARLY at epoch 298 (epsilon=1e-14)\n",
      "final loss=48.79334\n",
      "MSE of built-in linear regression(training):                     2.263924717762967e-28\n",
      "MSE of gradient descent solver for ridge regression (training):  47.15829064559563\n",
      "MSE of built-in solver for ridge regression (training):          0.03480412397500035\n",
      "MSE of built-in linear regression(test):                         50.89682328293875\n",
      "MSE of gradient descent solver for ridge regression (test):      54.6861607411059\n",
      "MSE of built-in solver for ridge regression (test):              4.5901649916210205\n"
     ]
    }
   ],
   "source": [
    "# Set regularization constant\n",
    "C = 1.0 # you can change it\n",
    "# Run gradient descent solver and compute its MSE\n",
    "w, b, losses = ridge_regression_GD(trainx, trainy, C, n_epochs=1000, lr=0.001, random_state=9)\n",
    "# Use built-in routine for linear regression and compute MSE\n",
    "lin_regr = linear_model.LinearRegression()\n",
    "lin_regr.fit(trainx, trainy)\n",
    "# Use built-in routine for ridge regression and compute MSE\n",
    "ridge_regr = linear_model.Ridge(alpha=1.0) # you can try different values\n",
    "ridge_regr.fit(trainx, trainy)\n",
    "# Print MSE values\n",
    "print(\"MSE of built-in linear regression(training):                    \", mean_squared_error(lin_regr.predict(trainx), trainy))\n",
    "print(\"MSE of gradient descent solver for ridge regression (training): \", compute_mse(w,b,trainx, trainy))\n",
    "print(\"MSE of built-in solver for ridge regression (training):         \", mean_squared_error(ridge_regr.predict(trainx), trainy))\n",
    "print(\"MSE of built-in linear regression(test):                        \", mean_squared_error(lin_regr.predict(testx), testy))\n",
    "print(\"MSE of gradient descent solver for ridge regression (test):     \", compute_mse(w,b,testx, testy))\n",
    "print(\"MSE of built-in solver for ridge regression (test):             \", mean_squared_error(ridge_regr.predict(testx), testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient descent solver for lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do:**</font> Define a procedure, **lasso_regression_GD**, that uses gradient descent to solve the lasso regression problem. It is invoked as follows:\n",
    "\n",
    "* `w,b,losses = lasso_regression_GD(x,y,C)`\n",
    "\n",
    "Here, the input consists of:\n",
    "* training data `trainx, trainy`, where `trainx` and `trainy` are numpy arrays of dimension `m`-by-`n` and `m`, respectively (if there are `m` training points and `n` features)\n",
    "* regularization constant `C`, we normally use the term **lambda**.\n",
    "\n",
    "The function should find the `n`-dimensional vector `w` and offset `b` that minimize the MSE loss function (with regularization constant `C`), and return:\n",
    "* `w` and `b`\n",
    "* `losses`, an array containing the MSE loss at each iteration\n",
    "\n",
    "<font color=\"magenta\">Advice:</font> First figure out the derivative, which has a relatively simple form. Next, when implementing gradient descent, think carefully about two issues.\n",
    "\n",
    "1. What is the step size (learning rate)?\n",
    "2. When has the procedure converged?\n",
    "\n",
    "Take the time to experiment with different ways of handling these.\n",
    "\n",
    "**Note:** You can use additional methods as helpers if you feel the need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def lasso_regression_GD(x,y,C, **kwargs):\n",
    "    return regression_GD_general(x, y, C, ridge=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out and print a graph of the loss values during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPPING EARLY at epoch 261 (epsilon=1e-14)\n",
      "final loss=47.73688\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEOCAYAAABiodtuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAaA0lEQVR4nO3de5ScdZ3n8fc3nZCEJBByg8gtCYlBhSUDUQERWZURVmWWYR2vjHgUL6w6M8yqu8zi4cwcFRUVUHcFPLtRFmTHy4BhD3KRy4hcpOOiXCSwEsLNQIdLIJAb4bd//J7qVFd1p6ua6nqqu96vc55TVc9Tl+8vT6c//fv9nnqeSCkhSVK1CWUXIEnqPIaDJKmO4SBJqmM4SJLqGA6SpDoTyy6gVebMmZMWLFhQdhmSNKasWrVqfUppbu36cRMOCxYsoLe3t+wyJGlMiYi1g613WEmSVMdwkCTVMRwkSXUMB0lSHcNBklTHcJAk1TEcJEl1DIcrr4Szzy67CknqKIbD1VfD179edhWS1FEMh6lTYdOmsquQpI5iOEyZksPBK+JJUj/DYerUfLtlS7l1SFIHMRwq4bB5c7l1SFIHMRwq4eC8gyT1MxwMB0mqYzgYDpJUx3CYMiXfGg6S1M9wcEJakuoYDg4rSVIdw8FwkKQ6hoPhIEl1DAcnpCWpjuFgz0GS6hgOHq0kSXUMB3sOklTHcJg0CSZMMBwkqUrbwiEizoqIVLOsq9r+lxFxdUT0FduOaVNhXvBHkmq0u+ewGphftRxctW0acAtweptr2nHBH0kSABPb/HkvpZTWDbYhpXQxQETMaW9J2HOQpBrt7jksiojHImJNRFwWEYva/PmDmzrVo5UkqUo7w+F24BTgeOBUYC/gloiYPdI3jIiPR0RvRPT29fWNvDJ7DpI0QNvCIaV0VUrpn1NKv08pXQe8q/j8D7+C97wwpbQ8pbR87ty5Iy/OcJCkAUo7lDWltBG4B1hSVg39DAdJGqC0cIiIKcCBwJ/KqqGfRytJ0gBtO1opIs4BVgIPA/OAM8mHr/6g2D4L2A+YWbxkcUQ8C6wb6ginlrHnIEkDtLPnsA/wI/J3HX4GbAEOTymtLbafAPxf4Ibi8UXF40+OemUerSRJA7St55BSet8w21cAK9pSTC17DpI0gOdWAsNBkmoYDmA4SFINwwF2HK2UUtmVSFJHMBxgxzUdtmwptw5J6hCGA3g1OEmqYTgA7Lprvn3xxXLrkKQOYTjAjnB44YVy65CkDmE4AEyblm/tOUgSYDhklXCw5yBJgOGQOawkSQMYDuCwkiTVMBzAnoMk1TAcwDkHSaphOIDDSpJUw3AAh5UkqYbhALDLLtDTYzhIUsFwAIjIQ0sOK0kSYDjssOuu9hwkqWA4VEybZjhIUsFwqHBYSZL6GQ4VDitJUj/DocJhJUnqZzhU7Lqrw0qSVDAcKuw5SFI/w6HCcJCkfoZDhcNKktTPcKiw5yBJ/QyHimnTYNu2vEhSlzMcKipnZnVoSZIMh35e8EeS+hkOFV7TQZL6GQ4VXg1OkvoZDhUOK0lSP8OhohIOGzeWW4ckdQDDoWLGjHz7/PPl1iFJHcBwqKiEgz0HSTIc+tlzkKR+hkOF4SBJ/QyHismToafHcJAkDIcdInLvwXCQJMNhAMNBkgDDYaAZMzxaSZIwHAay5yBJQBvDISLOiohUs6yr2h7Fcx6PiE0RcWNEvK5d9QGGgyQV2t1zWA3Mr1oOrtr2eeDvgc8ArweeBK6NiBltq85wkCQAJrb5815KKa2rXRkRAfwtcHZK6afFug+TA+IDwAVtqW76dMNBkmh/z2FRRDwWEWsi4rKIWFSsXwjsBVxTeWJKaRPwr8CRbavOnoMkAe0Nh9uBU4DjgVPJYXBLRMwu7gM8UfOaJ6q21YmIj0dEb0T09vX1vfIKPVpJkoA2DiullK6qfhwRtwEPAh8Gbqs8reZlMci66ve8ELgQYPny5UM+r2EzZsDWrXnZZZdX/HaSNFaVdihrSmkjcA+wBKjMQ9T2EuZR35sYPZ5fSZKAEsMhIqYABwJ/AtaQA+LYmu1vBm5pW1GGgyQBbRxWiohzgJXAw+QewZnANOAHKaUUEecC/xAR9wH3A/8V2Ahc2q4aDQdJytp5KOs+wI+AOUAfeZ7h8JTS2mL714CpwHeBPcgT2H+eUmrfb+rp0/Ot4SCpy7VzQvp9w2xPwFnFUg6vBidJgOdWGshhJUkCDIeBDAdJAgyHgXbbLd8+91y5dUhSyQyHapVw2LCh3DokqWSvKBwiYmpEvD0i9m9VQaWaNAmmTTMcJHW9psIhIlZExGnF/V2A35BPlrc6Io4fhfrab/fd4dlny65CkkrVbM/hHew4D9IJwAzyKS/OosxDUFtp5kx7DpK6XrPhsAf5GgsAxwE/TSk9CVwGvLaVhZXGnoMkNR0O64CDIqKH3Iu4rlg/HdjWysJKY89BkpoOh/8B/G/gbmA78Mti/RuB+1pYV3nsOUhSc6fPSCn9Y0TcA+wH/DiltLXY9BLw1VYXVwp7DpLU/LmVKtd4rln3g9aU0wEqPYeUIKLsaiSpFM0eyvpXEfHnVY+/GBGPRsTVETG/9eWVYObMfCW4zZvLrkSSStPsnMNZlTsRcShwBnA+MAn4RuvKKtHuu+dbh5YkdbFmw2F/YHVx/0Tg8pTS14DTgbe1srDSzJyZb52UltTFmg2HzeQvvkEOg8qhrBuq1o9t9hwkqekJ6V8B34iIm4HlwH8o1r8aeKSVhZXGnoMkNd1z+DSwlRwKn0wpPV6sPx64upWFlcaegyQ1/T2HR4F3D7L+b1tWUdnsOUjSyK4hHRFvJZ9LKQH3ppRuaGlVZbLnIEnNhUNE7A38C3AYUBlSelVE9AInVg0zjV3TpkFPjz0HSV2t2TmH88nnVFqcUto3pbQvsKRYd36riytFhOdXktT1mh1WOhY4JqW0prIipfRgRHyWHSfhG/tmzYKnny67CkkqTauuIf1yi96nM8yeDU89VXYVklSaZsPhl8D5EbFvZUVE7AecB1zfysJKNXu2PQdJXa3ZcPgssCvwYESsjYiHgD8CU4HPtLi28syaZc9BUldr9nsOjwCHRsSxwIFAAPcC/w/4JvBXLa+wDA4rSepyI/qeQ0rpWuDayuOIOAQ4qVVFlW72bHj+edi2DSZNKrsaSWq7Vk1Ijy+zZuVb5x0kdSnDYTCzZ+dbh5YkdSnDYTCVcLDnIKlLNTTnEBE/H+Ypu7Wgls5RGVay5yCpSzU6IT3cb8mngDXDPGfscFhJUpdrKBxSSh8Z7UI6isNKkrqccw6DmT4dJk605yCpaxkOg4nwi3CSuprhMBTPzCqpixkOQ5k9G9avL7sKSSqF4TCUefPgySfLrkKSSmE4DGXPPQ0HSV3LcBjKvHl5QnrbtrIrkaS2MxyGsuee+dZ5B0ldyHAYSiUcnnii3DokqQSlhUNEnBERKSK+U7Vuz4hYERGPR8SLEfGLiFhSSoHz5uVb5x0kdaFSwiEiDgdOBX5ftS6Ay4ElwL8H/gxYC1wXEdPaXqQ9B0ldrO3hEBG7A5cAHwWeqdq0BDgcOC2l9JuU0mrgU+TrU7+/3XXac5DUzcroOVwI/CSldH3N+snF7ebKipTSy8AW4Kg21bbDbrvB5Mn2HCR1pbaGQ0ScCiwGzhxk833kYaQvR8SsiNglIr4A7APMH+L9Ph4RvRHR29fX1+pi/SKcpK7VtnCIiKXAl4EPppS21m5PKW0DTgIOIF8f4kXg3wJXAdsHe8+U0oUppeUppeVz585tfdF77mnPQVJXavRiP61wBDAHuDvPPQPQAxwdEZ8EpqWUVgHLinmJXVJKfRFxO9Dbxjp3mDcP1q0r5aMlqUztHFa6HDgYWFa19AKXFff7exMppQ1FMCwBlgNXtLHOHew5SOpSbes5pJSeBZ6tXhcRLwBPp5TuLh6/B1hPnns4GDgPuDyldE276hxg/vzcc9i+HXp6SilBksrQad+Qng/8kDw5fT5wMWUcxlqxzz45GJyUltRl2jnnUCeldEzN4/PJodAZ9t473z76aO5FSFKX6LSeQ2ephMNjj5VbhyS1meGwM4aDpC5lOOzMvHkwcaLhIKnrGA47M2ECvOpVhoOkrmM4DGfvvQ0HSV3HcBjO3nvno5UkqYsYDsOx5yCpCxkOw9lnH9i4ETZsKLsSSWobw2E4++2Xb9euLbcOSWojw2E4Cxfm2zVryq1DktrIcBhOJRweeqjUMiSpnQyH4cyeDdOn23OQ1FUMh+FEwIIFhoOkrmI4NGLhQsNBUlcxHBpRCYeUyq5EktrCcGjEwoX5uw5PP112JZLUFoZDIypHLD34YLl1SFKbGA6NWLw43z7wQLl1SFKbGA6NWLw4n7579eqyK5GktjAcGjF5MixaBPfdV3YlktQWhkOjli41HCR1DcOhUQceCPffDy+/XHYlkjTqDIdGLV0KmzfDww+XXYkkjTrDoVEHHphvHVqS1AUMh0ZVwuHee8utQ5LawHBo1Ny5MH8+/O53ZVciSaPOcGjGsmWGg6SuYDg045BD8rDS1q1lVyJJo8pwaMayZbBtm/MOksY9w6EZy5blW4eWJI1zhkMzFi+GXXeF3/627EokaVQZDs3o6YHly+H228uuRJJGleHQrCOPzD2HTZvKrkSSRo3h0KwjjsiT0qtWlV2JJI0aw6FZRxyRb2+9tdw6JGkUGQ7NmjsXliyBX/+67EokadQYDiPxlrfAjTfCSy+VXYkkjQrDYSSOPRY2bIDe3rIrkaRRYTiMxNveBhFw7bVlVyJJo8JwGInZs+HQQ+Gaa8quRJJGheEwUscfn49Y6usruxJJajnDYaROOgm2b4crrii7EklqOcNhpA45BA44AH7yk7IrkaSWKy0cIuKMiEgR8Z2qddMj4tsR8WhEbIqI1RHxd2XVuFMRuffwy186tCRp3CklHCLicOBU4Pc1m74JvBM4GXgN8CXg7Ig4ub0VNujkk/N3HX74w7IrkaSWans4RMTuwCXAR4FnajYfCVycUrohpfRQSumHwG3AG9tcZmMOOggOPxwuughSKrsaSWqZMnoOFwI/SSldP8i2m4F3R8S+ABFxJLAM+EUb62vOqafC6tVwww1lVyJJLdPWcIiIU4HFwJlDPOWzwJ3AwxGxDbgJ+EJK6coh3u/jEdEbEb19ZY37v//9MG8efPWr5Xy+JI2CtoVDRCwFvgx8MKW0dYinfQZ4E3ACcBjwd8A5EXHcYE9OKV2YUlqeUlo+d+7c0Sh7eFOnwumn5y/E3XFHOTVIUotFatNYeUScAvxPYHvV6h4gAS8Ds4E+4D0ppSuqXvd9YEFK6e07e//ly5en3rLOdfTcc/mw1te9Lg8vRZRThyQ1KSJWpZSW165v57DS5cDB5DmEytILXFbcB5jEwPCgeNzZ38fYbTf4p3+Cm27yew+SxoWJ7fqglNKzwLPV6yLiBeDplNLdxeObyIeubgTWAm8B/hr4fLvqHLGPfQwuuAA+/el8Su9588quSJJGrNP+In8fcAf5UNd7gf9Mnrz+zs5e1BEmToSLL4Znn4VTTsmn1pCkMaptPYfBpJSOqXm8DvhIOdW0wEEHwbnnwmmnwec+B9/4hvMPksakUsNhXPrUp+APf4BvfQumTIEvfcmAkDTmGA6j4dxzYcsW+MpXYO3aPBcxfXrZVUlSwzptzmF8mDABvve93Gv40Y9g2TJYudJTbEgaMwyH0RIBZ5wBN96Yw+KEE/J5mC6/HLYO9R1ASeoMhsNoO/pouOce+P73Yd06OPFE2Gsv+OhH4ZJL4OGH7VFI6jht+4b0aCv1G9KN2rYNrrsOLr0Ufv7z/M1qgJkz4dWvhqVLYdEimDsX5szZscyYkU/TMWVKvp082UluSS0x1DekDYeybN8Od90FN98M996bz+y6ejU89tjwr43IQdHTk5cJE/Iy1P3K0mygjPbzR/oaSQNdcAG8+c0jeulQ4eDRSmXp6ckT1cuWDVz/0kvw1FOwfv2OZeNG2LQpL5s377i/fTu8/HJehrpf/bgZzf7RMJI/MkbyGYaJVG/GjJa/peHQaSZOhD33zIsklcQJaUlSHcNBklTHcJAk1TEcJEl1DAdJUh3DQZJUx3CQJNUxHCRJdcbN6TMioo983emRmAOsb2E5napb2gnd01bbOf60u637p5Tm1q4cN+HwSkRE72DnFhlvuqWd0D1ttZ3jT6e01WElSVIdw0GSVMdwyC4su4A26ZZ2Qve01XaOPx3RVuccJEl17DlIkuoYDpKkOoaDJKlO14dDRJwWEWsiYnNErIqIkV2ItUNExFkRkWqWdVXbo3jO4xGxKSJujIjXlVlzIyLi6Ij4eUQ8VrTplJrtw7YrIvaIiIsjYkOxXBwRM9vakGE00M4Vg+zf22qeMzkivh0R6yPiheL99mlrQ4YREf8lIu6IiOcioi8iVkbEQTXPGfP7tMF2duQ+7epwiIj3AucBXwb+DLgFuCoi9iu1sFduNTC/ajm4atvngb8HPgO8HngSuDYiWn8R2taaDtwN/A2waZDtjbTrUuBQ4HjguOL+xaNY80gM106A6xi4f/9dzfZzgZOA9wNvBnYDroyIntEoeISOAf4bcCTwVuAl4LqImFX1nPGwT49h+HZCJ+7TlFLXLsDtwEU16x4AvlJ2ba+gTWcBdw+xLYA/Af9QtW4q8DzwibJrb6KNG4FTmmkX8BogAW+qes5RxbqlZbepkXYW61YAV+7kNbsDW4EPVq3bF3gZeEfZbdpJ3dOB7cC7x/k+HdDOTt6nXdtziIhdgMOAa2o2XUNO+bFsUTEssSYiLouIRcX6hcBeVLU5pbQJ+FfGdpsbadcR5F+2t1S97tfAC4y9th8VEU9GxP0RcVFEzKvadhgwiYH/Fo8Af6Cz2zmDPJLxTPF4vO7T2nZWdNw+7dpwIJ/cqgd4omb9E+QfyrHqduAUcjf7VHJbbomI2exo13hrcyPt2gvoS8WfXQDF/ScZW23/BfDXwNvIQy5vAK6PiMnF9r3If5nWnrit0/fxecCdwK3F4/G6T2vbCR26TyeO1huPIbXfAoxB1o0ZKaWrqh8XE1sPAh8GKpNc46rNVYZr12BtHFNtTyldVvXwrohYRT4b8TuBn+3kpR3bzoj4Jnk46KiU0vaazeNmnw7Vzk7dp93cc1hPTuPa5J1H/V8rY1ZKaSNwD7AEqBy1NN7a3Ei71gHzIiIqG4v7cxnDbU8pPQ48St6/kNvZQ+4ZV+vIfRwR3yJPsr41pfRg1aZxtU930s46nbJPuzYcUkpbgVXAsTWbjmXgGOaYFhFTgAPJk3tryD9ox9ZsfzNju82NtOtW8mTgEVWvOwKYxhhue0TMAfYm71/IP9PbGPhvsQ958raj2hkR5wEfIP/CvK9m87jZp8O0c7Dnd8Y+LXv2vuQjB95LPgrgY8U/9HnkCa79y67tFbTpHOAt5Am9NwJXAs9V2gR8oXj8l8BBwGXA48CMsmsfpl3TgWXF8iLwxeL+fo22C7gKuAs4nPxL5C5gZdlta7SdxbZzitoXkA+TvJX8V2Z1O/878BjwdvIh2jeQx7l7ym5fVY3fLfbXW8m9g8oyveo5Y36fDtfOTt6npf/jlb0ApwEPAVvICX102TW9wvZU/gNtLX6Yfgq8tmp7kA93/ROwGbgJOKjsuhto1zHk8dXaZUWj7QJmAf+r+M/6XHF/Ztlta7Sd5EM5ryZPuG4lj0uvAPateY8pwLeBp8gBs7L2OWUvQ7QxAWc187Pa6ft0uHZ28j71rKySpDpdO+cgSRqa4SBJqmM4SJLqGA6SpDqGgySpjuEgSapjOEglKC5ic3fZdUhD8XsOGvciYgUwJ6X0rur7bfrsBeRTQbw+pdRbtX46MDml9FQ76pCa5VlZpRGIiInA9jTCv65SPiHixtZWJbWOw0rqGhFxFvnU5e+sulbvMcW2vYsLIz1TLP8nIpZUvzYi7o6IUyLij+TTrUyLiOMi4lfFa56OiKsj4jVVH7umuL2j+Lwbq9+v6v0nRMSZEfFIRGyJiLsi4i+qti8oXn9SRFwbES9GxL0RUX0ytkkRcX5xzeUtxXud3fJ/SHUFw0Hd5Bzgnxl4vd5bImJX8onMNpNPWngE+Xw+1xXbKhaSz675HuCQ4vnTyNf3fQP5vEgbgJXFlQYp1kO+vvF88knkBvM3wOfIJ5s7GPgX4GcRsazmeV8Czi8+/w7gsmKICuCzwInA+8ine34v+XriUtMcVlLXSCltjIhNwJaUUuV6AUTEh8gneftIZZgoIj5BPhnau8iBArALcHJKqfoc+j+t/oyI+Aj5BHBvAG4G+opNT1V/5iD+E3BOSunS4vEXI+LoYv2Hqp73rZTSyuKzziBfQWxZ8Vn7A/cDvyra8TAddOpqjS32HKR8jd6FwPMRsTEiNpJ7AHsAB1Q979GaYCAiDoiISyPijxHxHPniKxPIp9huSETsBryKfP3jajcDr61Z9/uq+48Xt5XrDa8gB8X9EfHdiHhnRPh/XCNiz0HKv8zvJA/H1Hq66v4Lg2xfST41+ieK25eAe8m9jGYNNrldu25b/4aUUnERtAnF498WR0cdR75+wA+A30XEsSmll0dQj7qY4aBus5V8ycVqvyVfwnF9SunZRt8oImaTLxL1H1NKNxTrDmXg/6utxW3tZ/ZLKT0XEY+Try98fdWmo8hB07CU0vPAj4EfF4ft3gYsJg83SQ0zHNRtHgKOj4il5AunbAAuIY/tXxERXySP1e8L/AXwvZTSA0O81zPka5GfGhGPkC/t+HVy76HiSWAT8I6IeAjYnFLaMMh7fR34x4h4gHzRqQ+RL4l5WKMNi4jTyRPpd5J7GB8gz3882uh7SBWOR6rbXAT8AeglTxa/KaX0InA08CD5r+77yEMye5ADYFDFUM17gX8D3E2+JOSZ5MNcK895iXwU0cfIcwRXDPF255MD4mvFe50InJRSurOJtj1PPuLpN+Te0DLg+KJ9UlP8hrQkqY49B0lSHcNBklTHcJAk1TEcJEl1DAdJUh3DQZJUx3CQJNUxHCRJdf4/N81Ge2LAxAsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|W|=10.83\n",
      "Features that have been killed by lasso (|w| <= 0.06) (as indexes):\n",
      " (array([ 0,  7, 33, 62, 80], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# Set regularization constant\n",
    "C = 1.0 # you can try different values for C\n",
    "# Run gradient descent solver\n",
    "w, b, losses = lasso_regression_GD(trainx,trainy,C, lr=0.001, random_state=9)\n",
    "# Plot the losses\n",
    "plt.plot(losses,'r')\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('|W|={:.2f}'.format(np.linalg.norm(w)))\n",
    "# print('W=', w)\n",
    "# sorted_args = np.argsort(np.abs(w))\n",
    "thr = 0.06\n",
    "print(f'Features that have been killed by lasso (|w| <= {thr}) (as indexes):\\n', np.where(np.abs(w) <= thr) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the gradient descent solver for lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the regressor found by your gradient descent procedure to that returned by the built-in ridge regression solver in `sklearn`. We will compare them by their resulting MSE values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPPING EARLY at epoch 261 (epsilon=1e-14)\n",
      "final loss=47.73688\n",
      "MSE of built-in linear regression(training):                     2.263924717762967e-28\n",
      "MSE of gradient descent solver for lasso regression (training):  47.15803345620624\n",
      "MSE of built-in solver for lasso regression (training):          8.782996430353922\n",
      "MSE of built-in linear regression(test):                         50.89682328293875\n",
      "MSE of gradient descent solver for lasso regression (test):      54.67061012744028\n",
      "MSE of built-in solver for lasso regression (test):              9.566046105001256\n"
     ]
    }
   ],
   "source": [
    "# Set regularization constant\n",
    "C = 1.0 # you can change it\n",
    "# Run gradient descent solver and compute its MSE\n",
    "w, b, losses = lasso_regression_GD(trainx,trainy,C, random_state=9)\n",
    "# Use built-in routine for ridge regression and compute MSE\n",
    "lasso_regr = linear_model.Lasso(alpha=1.0) # you can try different values\n",
    "lasso_regr.fit(trainx,trainy)\n",
    "# Print MSE values\n",
    "print(\"MSE of built-in linear regression(training):                    \", mean_squared_error(lin_regr.predict(trainx), trainy))\n",
    "print(\"MSE of gradient descent solver for lasso regression (training): \", compute_mse(w,b,trainx, trainy))\n",
    "print(\"MSE of built-in solver for lasso regression (training):         \", mean_squared_error(lasso_regr.predict(trainx), trainy))\n",
    "print(\"MSE of built-in linear regression(test):                        \", mean_squared_error(lin_regr.predict(testx), testy))\n",
    "print(\"MSE of gradient descent solver for lasso regression (test):     \", compute_mse(w,b,testx, testy))\n",
    "print(\"MSE of built-in solver for lasso regression (test):             \", mean_squared_error(lasso_regr.predict(testx), testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With regularization diabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization DISABLED\n",
      "STOPPING EARLY at epoch 167 (epsilon=1e-14)\n",
      "final loss=47.62961\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|W|=10.83\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent solver\n",
    "print('Regularization DISABLED')\n",
    "w, b, losses = lasso_regression_GD(trainx,trainy,C=0.0, lr=0.001, random_state=9)\n",
    "# Plot the losses\n",
    "plt.plot(losses,'r')\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('|W|={:.2f}'.format(np.linalg.norm(w)))\n",
    "# thr = 0.06\n",
    "# print(f'Features that have been killed by lasso (|w| <= {thr}) (as indexes):\\n', np.where(np.abs(w) <= thr) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Documents all the results in the report.\n",
    "2. Try with a large value of C (e.g., 20) for lasso and check teh weights and MSE. What do you observe?\n",
    "3. Compare the coefficients (parameter values) for ridge and lasso for the best setup. What do you observe? Can you explain?\n",
    "4. Compare MSE of linear, ridge, and lasso. What do you observe?\n",
    "5. Which among the ridge and lasso gives teh best results on the test? Can you explain why?\n",
    "6. Can the lasso regression retrieve the 10 features which were used in the equation for y? List them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}